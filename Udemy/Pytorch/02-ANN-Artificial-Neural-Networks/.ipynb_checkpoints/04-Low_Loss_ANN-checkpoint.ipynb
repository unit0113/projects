{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pierian-Data-Logo.PNG\">\n",
    "<br>\n",
    "<strong><center>Copyright 2019. Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Artificial Neural Network Code Along\n",
    "In the last section we took in four continuous variables (lengths) to perform a classification. In this section we'll combine continuous and categorical data to perform a regression. The goal is to estimate the cost of a cab ride from several inputs. The inspiration behind this code along is a recent <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>Kaggle competition</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NYC Taxi Fares dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-03-01-23:58:01.01</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2010-03-01 23:58:01 UTC</td>\n",
       "      <td>-73.972751</td>\n",
       "      <td>40.763546</td>\n",
       "      <td>-73.986086</td>\n",
       "      <td>40.760804</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-23:58:10.01</th>\n",
       "      <td>11.3</td>\n",
       "      <td>2010-03-01 23:58:10 UTC</td>\n",
       "      <td>-73.937198</td>\n",
       "      <td>40.804350</td>\n",
       "      <td>-73.928214</td>\n",
       "      <td>40.772218</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-23:58:30.01</th>\n",
       "      <td>6.9</td>\n",
       "      <td>2010-03-01 23:58:30 UTC</td>\n",
       "      <td>-73.971783</td>\n",
       "      <td>40.794864</td>\n",
       "      <td>-73.966151</td>\n",
       "      <td>40.789576</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-23:59:42.01</th>\n",
       "      <td>6.9</td>\n",
       "      <td>2010-03-01 23:59:42 UTC</td>\n",
       "      <td>-74.001461</td>\n",
       "      <td>40.731025</td>\n",
       "      <td>-73.987639</td>\n",
       "      <td>40.721758</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-23:59:44.01</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2010-03-01 23:59:44 UTC</td>\n",
       "      <td>-73.971741</td>\n",
       "      <td>40.754337</td>\n",
       "      <td>-73.952507</td>\n",
       "      <td>40.778123</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fare_amount          pickup_datetime  \\\n",
       "2010-03-01-23:58:01.01          5.7  2010-03-01 23:58:01 UTC   \n",
       "2010-03-01-23:58:10.01         11.3  2010-03-01 23:58:10 UTC   \n",
       "2010-03-01-23:58:30.01          6.9  2010-03-01 23:58:30 UTC   \n",
       "2010-03-01-23:59:42.01          6.9  2010-03-01 23:59:42 UTC   \n",
       "2010-03-01-23:59:44.01          6.5  2010-03-01 23:59:44 UTC   \n",
       "\n",
       "                        pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "2010-03-01-23:58:01.01        -73.972751        40.763546         -73.986086   \n",
       "2010-03-01-23:58:10.01        -73.937198        40.804350         -73.928214   \n",
       "2010-03-01-23:58:30.01        -73.971783        40.794864         -73.966151   \n",
       "2010-03-01-23:59:42.01        -74.001461        40.731025         -73.987639   \n",
       "2010-03-01-23:59:44.01        -73.971741        40.754337         -73.952507   \n",
       "\n",
       "                        dropoff_latitude  passenger_count  hour  \n",
       "2010-03-01-23:58:01.01         40.760804                1    23  \n",
       "2010-03-01-23:58:10.01         40.772218                1    23  \n",
       "2010-03-01-23:58:30.01         40.789576                1    23  \n",
       "2010-03-01-23:59:42.01         40.721758                1    23  \n",
       "2010-03-01-23:59:44.01         40.778123                1    23  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/NYCTaxiFares.csv',index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fare_amount', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = df.columns\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fare_amount'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def haversine_distance(df, start_lat, end_lat, start_lng, end_lng, prefix):\n",
    "    \"\"\"\n",
    "    calculates haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    R = 6371  #radius of earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[start_lat])\n",
    "    phi2 = np.radians(df[end_lat])\n",
    "    \n",
    "    delta_phi = np.radians(df[end_lat]-df[start_lat])\n",
    "    delta_lambda = np.radians(df[end_lng]-df[start_lng])\n",
    "    \n",
    "        \n",
    "    a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (R * c) #in kilometers\n",
    "    df[prefix+'distance_km'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "haversine_distance(df, 'pickup_latitude', 'dropoff_latitude', 'pickup_longitude', 'dropoff_longitude', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-03-01-00:00:05.01</th>\n",
       "      <td>23.07</td>\n",
       "      <td>2010-03-01 00:00:05 UTC</td>\n",
       "      <td>-73.955364</td>\n",
       "      <td>40.776753</td>\n",
       "      <td>-73.871019</td>\n",
       "      <td>40.774185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.108018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-00:00:26.01</th>\n",
       "      <td>6.10</td>\n",
       "      <td>2010-03-01 00:00:26 UTC</td>\n",
       "      <td>-73.977562</td>\n",
       "      <td>40.752204</td>\n",
       "      <td>-73.979139</td>\n",
       "      <td>40.764011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.319581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-00:00:30.01</th>\n",
       "      <td>4.90</td>\n",
       "      <td>2010-03-01 00:00:30 UTC</td>\n",
       "      <td>-73.988141</td>\n",
       "      <td>40.759481</td>\n",
       "      <td>-73.992240</td>\n",
       "      <td>40.748884</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.227875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-00:00:30.02</th>\n",
       "      <td>8.50</td>\n",
       "      <td>2010-03-01 00:00:30 UTC</td>\n",
       "      <td>-73.981855</td>\n",
       "      <td>40.775459</td>\n",
       "      <td>-73.968213</td>\n",
       "      <td>40.751485</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.902838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01-00:01:07.01</th>\n",
       "      <td>6.10</td>\n",
       "      <td>2010-03-01 00:01:07 UTC</td>\n",
       "      <td>-73.904717</td>\n",
       "      <td>40.879041</td>\n",
       "      <td>-73.921539</td>\n",
       "      <td>40.881664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.444022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fare_amount          pickup_datetime  \\\n",
       "2010-03-01-00:00:05.01        23.07  2010-03-01 00:00:05 UTC   \n",
       "2010-03-01-00:00:26.01         6.10  2010-03-01 00:00:26 UTC   \n",
       "2010-03-01-00:00:30.01         4.90  2010-03-01 00:00:30 UTC   \n",
       "2010-03-01-00:00:30.02         8.50  2010-03-01 00:00:30 UTC   \n",
       "2010-03-01-00:01:07.01         6.10  2010-03-01 00:01:07 UTC   \n",
       "\n",
       "                        pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "2010-03-01-00:00:05.01        -73.955364        40.776753         -73.871019   \n",
       "2010-03-01-00:00:26.01        -73.977562        40.752204         -73.979139   \n",
       "2010-03-01-00:00:30.01        -73.988141        40.759481         -73.992240   \n",
       "2010-03-01-00:00:30.02        -73.981855        40.775459         -73.968213   \n",
       "2010-03-01-00:01:07.01        -73.904717        40.879041         -73.921539   \n",
       "\n",
       "                        dropoff_latitude  passenger_count  hour  distance_km  \n",
       "2010-03-01-00:00:05.01         40.774185                1     0     7.108018  \n",
       "2010-03-01-00:00:26.01         40.764011                1     0     1.319581  \n",
       "2010-03-01-00:00:30.01         40.748884                1     0     1.227875  \n",
       "2010-03-01-00:00:30.02         40.751485                1     0     2.902838  \n",
       "2010-03-01-00:01:07.01         40.881664                1     0     1.444022  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = cont_cols + ['distance_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model class\n",
    "For this exercise we're using the Iris dataset. Since a single straight line can't classify three flowers we should include at least one hidden layer in our model.\n",
    "\n",
    "In the forward section we'll use the <a href='https://en.wikipedia.org/wiki/Rectifier_(neural_networks)'>rectified linear unit</a> (ReLU)  function<br>\n",
    "$\\quad f(x)=max(0,x)$<br>\n",
    "as our activation function. This is available as a full module <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong><tt>torch.nn.ReLU</tt></strong></a> or as just a functional call <a href='https://pytorch.org/docs/stable/nn.html#id27'><strong><tt>torch.nn.functional.relu</tt></strong></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=30, h2=30,h3=30, out_features=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)  \n",
    "        self.fc2 = nn.Linear(h2, h3) # hidden layer\n",
    "        self.out = nn.Linear(h3, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the Model class using parameter defaults:\n",
    "torch.manual_seed(101)\n",
    "model = Model(5,40,40,40,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[cont_cols].values\n",
    "y = df['fare_amount'].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 139.58552551\n",
      "epoch: 11  loss: 63.49932480\n",
      "epoch: 21  loss: 60.91341782\n",
      "epoch: 31  loss: 54.18982697\n",
      "epoch: 41  loss: 49.22862625\n",
      "epoch: 51  loss: 45.51780319\n",
      "epoch: 61  loss: 41.09418869\n",
      "epoch: 71  loss: 36.73507309\n",
      "epoch: 81  loss: 32.19643021\n",
      "epoch: 91  loss: 27.59387016\n",
      "epoch: 101  loss: 23.07151031\n",
      "epoch: 111  loss: 18.81528664\n",
      "epoch: 121  loss: 15.03000069\n",
      "epoch: 131  loss: 11.91219711\n",
      "epoch: 141  loss: 9.58362293\n",
      "epoch: 151  loss: 8.04716682\n",
      "epoch: 161  loss: 7.17847347\n",
      "epoch: 171  loss: 6.77299261\n",
      "epoch: 181  loss: 6.62477779\n",
      "epoch: 191  loss: 6.58645487\n",
      "epoch: 201  loss: 6.58148336\n",
      "epoch: 211  loss: 6.58203030\n",
      "epoch: 221  loss: 6.58212852\n",
      "epoch: 231  loss: 6.58181334\n",
      "epoch: 241  loss: 6.58156443\n",
      "epoch: 251  loss: 6.58146286\n",
      "epoch: 261  loss: 6.58143663\n",
      "epoch: 271  loss: 6.58142805\n",
      "epoch: 281  loss: 6.58141994\n",
      "epoch: 291  loss: 6.58141136\n",
      "epoch: 301  loss: 6.58140182\n",
      "epoch: 311  loss: 6.58139324\n",
      "epoch: 321  loss: 6.58138418\n",
      "epoch: 331  loss: 6.58137465\n",
      "epoch: 341  loss: 6.58136559\n",
      "epoch: 351  loss: 6.58135605\n",
      "epoch: 361  loss: 6.58134604\n",
      "epoch: 371  loss: 6.58133650\n",
      "epoch: 381  loss: 6.58132648\n",
      "epoch: 391  loss: 6.58131599\n",
      "epoch: 401  loss: 6.58130598\n",
      "epoch: 411  loss: 6.58129549\n",
      "epoch: 421  loss: 6.58128500\n",
      "epoch: 431  loss: 6.58127356\n",
      "epoch: 441  loss: 6.58126259\n",
      "epoch: 451  loss: 6.58125210\n",
      "epoch: 461  loss: 6.58124065\n",
      "epoch: 471  loss: 6.58122921\n",
      "epoch: 481  loss: 6.58121729\n",
      "epoch: 491  loss: 6.58120584\n",
      "epoch: 501  loss: 6.58119345\n",
      "epoch: 511  loss: 6.58118200\n",
      "epoch: 521  loss: 6.58116961\n",
      "epoch: 531  loss: 6.58115768\n",
      "epoch: 541  loss: 6.58114481\n",
      "epoch: 551  loss: 6.58113194\n",
      "epoch: 561  loss: 6.58111954\n",
      "epoch: 571  loss: 6.58110619\n",
      "epoch: 581  loss: 6.58109331\n",
      "epoch: 591  loss: 6.58108044\n",
      "epoch: 601  loss: 6.58106661\n",
      "epoch: 611  loss: 6.58105326\n",
      "epoch: 621  loss: 6.58103943\n",
      "epoch: 631  loss: 6.58102560\n",
      "epoch: 641  loss: 6.58101177\n",
      "epoch: 651  loss: 6.58099747\n",
      "epoch: 661  loss: 6.58098269\n",
      "epoch: 671  loss: 6.58096886\n",
      "epoch: 681  loss: 6.58095407\n",
      "epoch: 691  loss: 6.58093929\n",
      "epoch: 701  loss: 6.58092499\n",
      "epoch: 711  loss: 6.58090925\n",
      "epoch: 721  loss: 6.58089447\n",
      "epoch: 731  loss: 6.58087873\n",
      "epoch: 741  loss: 6.58086348\n",
      "epoch: 751  loss: 6.58084774\n",
      "epoch: 761  loss: 6.58083200\n",
      "epoch: 771  loss: 6.58081627\n",
      "epoch: 781  loss: 6.58080006\n",
      "epoch: 791  loss: 6.58086348\n",
      "epoch: 801  loss: 6.60858727\n",
      "epoch: 811  loss: 6.59079218\n",
      "epoch: 821  loss: 6.58567572\n",
      "epoch: 831  loss: 6.58278275\n",
      "epoch: 841  loss: 6.58161592\n",
      "epoch: 851  loss: 6.58099079\n",
      "epoch: 861  loss: 6.58069515\n",
      "epoch: 871  loss: 6.58068562\n",
      "epoch: 881  loss: 6.58065796\n",
      "epoch: 891  loss: 6.58063555\n",
      "epoch: 901  loss: 6.58061457\n",
      "epoch: 911  loss: 6.58059835\n",
      "epoch: 921  loss: 6.58058214\n",
      "epoch: 931  loss: 6.58056545\n",
      "epoch: 941  loss: 6.58054924\n",
      "epoch: 951  loss: 6.58053255\n",
      "epoch: 961  loss: 6.58051634\n",
      "epoch: 971  loss: 6.58053541\n",
      "epoch: 981  loss: 6.58679342\n",
      "epoch: 991  loss: 6.58083439\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG4FJREFUeJzt3XmUlfWd5/H3Byg2FQqkVKSIBUg0\n0biWxl1Hk3YZW+zWtNomIUpC7HEmxmTicjLT9uScnGNGR227MyYkLrjEGLfR9hiXxi2mBS1cAUUQ\nEEpZyrAIKEvBd/64T0FZ3uIWBc997q3n8zqnzr3P7z733u9TD/qp37P8fooIzMzMOuqVdQFmZlaZ\nHBBmZlaUA8LMzIpyQJiZWVEOCDMzK8oBYWZmRTkgzMysKAeEmZkV5YAwM7Oi+mRdwI4YNmxYNDQ0\nZF2GmVlVmT59+kcRUVdqvaoOiIaGBpqamrIuw8ysqkh6vyvr+RCTmZkV5YAwM7OiHBBmZlaUA8LM\nzIpKLSAk3SZpmaQZRV7775JC0rBkWZJuljRX0puSDkurLjMz65o0exB3AKd1bJQ0Evg6sLBd8+nA\n2ORnInBLinWZmVkXpBYQEfECsLzISzcCVwDtp7IbB9wZBVOBWknD06rNzMxKK+s5CElnAR9ExBsd\nXhoBLGq33Jy0pWL2ktXc8NRsPlqzPq2vMDOremULCEkDgZ8C/1js5SJtRSfLljRRUpOkppaWlm7V\nMmfZam5+Zi7L127o1vvNzPKgnD2IMcAo4A1JC4B64FVJe1HoMYxst2498GGxD4mISRHRGBGNdXUl\n7xQvSkkeRdEIMjMzKGNARMRbEbFHRDRERAOFUDgsIpYAjwLfTq5mOgpYFRGL06pFSX8lindSzMyM\ndC9zvRd4CdhPUrOkCdtY/XFgHjAX+A3wX9KqC4ofzzIzs89KbbC+iLigxOsN7Z4HcGlatXReQ7m/\n0cyseuTyTuoth5gcEGZmncplQLQdZPI5CDOzzuUyINyDMDMrLZ8BkXUBZmZVIJ8BId8HYWZWSj4D\nInn0OQgzs87lMyB8jMnMrKRcBkQbH2IyM+tcLgNi61AbZmbWmXwGxJbB+hwRZmadyWVA4B6EmVlJ\nuQyILVcxOSHMzDqVz4DQ1gtdzcysuHwGRPLoHoSZWefyGRC+D8LMrKRcBkQbdyDMzDqXy4DwnNRm\nZqXlMyC2DPfthDAz60w+AyJ5dDyYmXUulwGBJwwyMysplwEhTzlqZlZSagEh6TZJyyTNaNd2naR3\nJL0p6WFJte1eu1rSXEmzJZ2aVl2F70qeOB/MzDqVZg/iDuC0Dm1PAwdGxEHAu8DVAJK+DJwPHJC8\n5/9K6p1WYb4NwsystNQCIiJeAJZ3aHsqIlqTxalAffJ8HPD7iFgfEfOBucCRadW2pZ60v8DMrIpl\neQ7iYuCPyfMRwKJ2rzUnbZ8jaaKkJklNLS0t3fpiz0ltZlZaJgEh6adAK3BPW1OR1Yr+7zsiJkVE\nY0Q01tXVdfP7277ACWFm1pk+5f5CSeOBM4FTYuudas3AyHar1QMfplZD8ugehJlZ58rag5B0GnAl\ncFZEfNLupUeB8yX1kzQKGAu8nF4dhUfng5lZ51LrQUi6FzgJGCapGbiGwlVL/YCnk/MAUyPikoiY\nKekPwCwKh54ujYhNadWGpxw1MysptYCIiAuKNN+6jfV/Dvw8rXracw/CzKy0nN5JbWZmpeQyILZw\nF8LMrFO5DIgt90E4IczMOpXPgEgefY7azKxz+QwID/dtZlZSPgNiy3DfZmbWmXwGhKccNTMrKZcB\n0cbxYGbWuVwGhHwjhJlZSbkMiDY+wmRm1rlcBoTwnKNmZqXkMyB8mauZWUn5DohsyzAzq2j5DAg8\n5aiZWSn5DAhPOWpmVlI+AyJ5dA/CzKxz+QwI3wdhZlZSLgOijTsQZmady2lAeE5qM7NSchkQPsRk\nZlZaagEh6TZJyyTNaNc2VNLTkuYkj0OSdkm6WdJcSW9KOiytusAnqc3MuiLNHsQdwGkd2q4CpkTE\nWGBKsgxwOjA2+ZkI3JJiXZ5y1MysC1ILiIh4AVjeoXkcMDl5Phk4u137nVEwFaiVNDyt2tyDMDMr\nrdznIPaMiMUAyeMeSfsIYFG79ZqTtlR4LCYzs9Iq5SR1sdPGRf/3LWmipCZJTS0tLd38Mp+lNjMr\npdwBsbTt0FHyuCxpbwZGtluvHviw2AdExKSIaIyIxrq6uh0qxh0IM7POlTsgHgXGJ8/HA4+0a/92\ncjXTUcCqtkNRafCc1GZmpfVJ64Ml3QucBAyT1AxcA1wL/EHSBGAh8I1k9ceBM4C5wCfARWnV1Z7j\nwcysc6kFRERc0MlLpxRZN4BL06qlI3lCOTOzkirlJHVZ+T4IM7PS8hkQyaNPQZiZdS6fAeEpR83M\nSspnQPg+CDOzknIZEG18iMnMrHO5DAjPSW1mVlo+AyJ5dA/CzKxzuQwIfJLazKykXAbElpPU7kKY\nmXUqnwHhHoSZWUn5DIjk0R0IM7PO5TMg5PsgzMxKyWVAtPFw32ZmnctlQLT1H3738kKemLEk01rM\nzCpVPgMiSYh3l67hkrunZ1uMmVmFymdAeCwmM7OSchkQzgczs9JyGRC+iMnMrLR8BkTWBZiZVYF8\nBoS7EGZmJeUyIMzMrLRMAkLS5ZJmSpoh6V5J/SWNkjRN0hxJ90nqm9r3p/XBZmY9SNkDQtII4AdA\nY0QcCPQGzgd+AdwYEWOBFcCE9GpI65PNzHqOrA4x9QEGSOoDDAQWAycDDySvTwbOTuvLfR+EmVlp\nZQ+IiPgAuB5YSCEYVgHTgZUR0Zqs1gyMSKsG9yDMzErL4hDTEGAcMArYG9gFOL3IqkVH0pM0UVKT\npKaWlpb0CjUzy7kuBYSkMZL6Jc9PkvQDSbXd/M6vAfMjoiUiNgIPAccAtckhJ4B64MNib46ISRHR\nGBGNdXV13Sqgl7sQZmYldbUH8SCwSdK+wK0U/vr/XTe/cyFwlKSBKtyQcAowC3gWODdZZzzwSDc/\nv6TevT4bEJs2e9hvM7OOuhoQm5PzA38D3BQRlwPDu/OFETGNwsnoV4G3khomAVcCP5I0F9idQhCl\nokM+sHHT5rS+ysysavUpvQoAGyVdQOEv+79O2mq6+6URcQ1wTYfmecCR3f3M7dHxTuoNmzbTv6Z3\nOb7azKxqdLUHcRFwNPDziJgvaRRwd3plldfGVvcgzMw66lIPIiJmUbi5re0qpN0i4to0CyunjZt8\nDsLMrKOuXsX0nKRBkoYCbwC3S7oh3dLKZ4N7EGZmn9PVQ0yDI+Jj4G+B2yPicAqXq/YIG3yS2szs\nc7oaEH0kDQf+DngsxXoy4auYzMw+r6sB8TPgSeC9iHhF0mhgTnpllZcDwszs87p6kvp+4P52y/OA\nc9IqqtwcEGZmn9fVk9T1kh6WtEzSUkkPSqpPu7hy2dDqq5jMzDrq6iGm24FHKQyuNwL4t6StR3AP\nwszs87oaEHURcXtEtCY/dwDdGymvAjW9v4Ln3/XIsGZm7XU1ID6S9E1JvZOfbwJ/SbOwcrp5yhzG\n3/Zy1mWYmVWUrgbExRQucV1CYZKfcykMv9GjrFnfWnolM7Oc6FJARMTCiDgrIuoiYo+IOJvCTXM9\nypJV67IuwcysYuzIjHI/2mlVVIjV6zZmXYKZWcXYkYDocdOyfbzOh5jMzNrsSED0uJsH3IMwM9tq\nm3dSS1pN8SAQMCCVijL08afuQZiZtdlmQETEbuUqpBK4B2FmttWOHGLqcVb7HISZ2RYOiHY+dg/C\nzGwLB0Q77kGYmW2VSUBIqpX0gKR3JL0t6WhJQyU9LWlO8jiknDXtNag/H3/qHoSZWZusehD/DDwR\nEfsDBwNvA1cBUyJiLDAlWU7NMz8+kacuP2HL8oghA2hZs55fPjuXtR5yw8ysaxMG7UySBgEnAN8B\niIgNwAZJ44CTktUmA88BV6ZVx+i6XT+zPHSXvjw9aylvNq/ikw2t/OTU/dP6ajOzqlD2gABGAy3A\n7ZIOBqYDlwF7RsRigIhYLGmPchRz43kH89rClZ8ZqO+DFZ+W46vNzCpaFoeY+gCHAbdExKHAWrbj\ncJKkiZKaJDW1tOz4HA5/c2g9Pxt3IIP612xp+9CD9pmZZRIQzUBzRExLlh+gEBhLJQ0HSB6XFXtz\nREyKiMaIaKyr23lzFg3qv7Uz5R6EmVkGARERS4BFkvZLmk4BZlGY0nR80jYeeKScdQ0asLUHseTj\ndbR6GlIzy7kszkEA/DfgHkl9gXkUJh/qBfxB0gRgIfCNchb0t4fV88SMJRyw9yAmv/Q+S1evZ0Rt\njxtuysysyzIJiIh4HWgs8tIp5a6lzdBd+vLAPxzD8++2MPml92le/okDwsxyzXdSd9AWChMmN3Hn\nSwsyrcXMLEsOiA7qhxQCYs36Vv7xkZls9LkIM8spB0QH/Wt6c17jyC3Ls5eszrAaM7PsOCCKuPac\nr/DCT/4TAG80r8y4GjOzbDggipDEyKEDGDKwhjcWOSDMLJ8cEJ2QxMEja3lq1lI+WrM+63LMzMrO\nAbENpx6wFys/2cjJ1z/Hyk82ZF2OmVlZOSC24fwjRnLduQfx8bpWnp61NOtyzMzKygGxDZI49/B6\nRtQO4MmZS7Iux8ysrBwQJUji9AP34vl3W1j1iWecM7P8cEB0wdmHjmDjpuC6p94hIrIux8ysLBwQ\nXXDgiMFMPGE0d09dyHOzd3wOCjOzauCA6KKfnLofdbv14+6p72ddiplZWTgguqimdy/+rrGeZ2cv\n48OVnlDIzHo+B8R2OP+ILxDAHf+xIOtSzMxS54DYDiOHDuScw+q5/c/zmf/R2qzLMTNLlQNiO11x\n6n707d2L6558J+tSzMxS5YDYTnsM6s+3jm7giRlLaF7xSdblmJmlxgHRDd8+eh8kccefF2RdiplZ\nahwQ3bB37QDGHbI3d019n8WrfEWTmfVMDohuuvxrXyQC/vWZuVmXYmaWiswCQlJvSa9JeixZHiVp\nmqQ5ku6T1Der2rpi5NCBnHP4CO6f3kzLas8XYWY9T5Y9iMuAt9st/wK4MSLGAiuACZlUtR0mnjCG\njZs2c/uf52ddipnZTpdJQEiqB/4z8NtkWcDJwAPJKpOBs7OobXuMGrYLZxw4nLumvs/qdR7p1cx6\nlqx6EDcBVwCbk+XdgZUR0ZosNwMjir1R0kRJTZKaWlqyHzjvkhPHsHpdK79/eVHWpZiZ7VRlDwhJ\nZwLLImJ6++YiqxYdVzsiJkVEY0Q01tXVpVLj9vhK/WCOGbM7t744nw2tm0u/wcysSmTRgzgWOEvS\nAuD3FA4t3QTUSuqTrFMPfJhBbd3y/RPHsOTjdTz6RtWUbGZWUtkDIiKujoj6iGgAzgeeiYgLgWeB\nc5PVxgOPlLu27jph7DD232s3Jr3wHps3e0IhM+sZKuk+iCuBH0maS+GcxK0Z19Nlkvj+iaN5d+ka\nnp29LOtyzMx2ikwDIiKei4gzk+fzIuLIiNg3Ir4REVV1c8GZB+3N3oP785s/zcu6FDOznaKSehBV\nraZ3L75zbANT5y1nxgersi7HzGyHOSB2ovOP/AK79uvjXoSZ9QgOiJ1oUP8azjtiJI+9udjTkppZ\n1XNA7GQXHdsAeFpSM6t+DoidrH7IQE4/cC/unbaQNetbS7/BzKxCOSBS8N3jR7N6fSv3veLhN8ys\nejkgUnDIyFqOaBjCbS/Op3WTh98ws+rkgEjJd48fzQcrP+WJmUuyLsXMrFscECn52pf2pGH3gfzm\nT/OJ8PAbZlZ9HBAp6d1LTDhuFG8sWsn091dkXY6Z2XZzQKTonMPrqR1Y4xvnzKwqOSBSNLBvHy78\n6hd4atZSFny0NutyzMy2iwMiZeOPbqCmVy9u87zVZlZlHBAp22NQf846ZG/ub2pm5Scbsi7HzKzL\nHBBl8N3jR/Hpxk3cM21h1qWYmXWZA6IM9t9rEMePHcYd/7GAdRs3ZV2OmVmXOCDK5JITx9Cyej0P\nv/ZB1qWYmXWJA6JMjhmzO18ZMZhJL8xjk+etNrMq4IAoE0lccuIY5n+0lqc8/IaZVQEHRBmdduBe\nNOw+kF89/56H3zCzilf2gJA0UtKzkt6WNFPSZUn7UElPS5qTPA4pd21p691LfO+E0bzRvIqX5v0l\n63LMzLYpix5EK/DjiPgScBRwqaQvA1cBUyJiLDAlWe5xzjmsnmG79uVXz3v4DTOrbGUPiIhYHBGv\nJs9XA28DI4BxwORktcnA2eWurRz61/TmomNH8cK7Lcz8cFXW5ZiZdSrTcxCSGoBDgWnAnhGxGAoh\nAuyRXWXp+uZR+7Brvz788tm5WZdiZtapzAJC0q7Ag8API+Lj7XjfRElNkppaWlrSKzBFgwfUcPFx\no3j8rSXuRZhZxcokICTVUAiHeyLioaR5qaThyevDgWXF3hsRkyKiMSIa6+rqylNwCiYcN4pB/ftw\n07/PyboUM7OisriKScCtwNsRcUO7lx4FxifPxwOPlLu2cho8oIbvHT+ap2ct5a1m9yLMrPJk0YM4\nFvgWcLKk15OfM4Brga9LmgN8PVnu0b5zbAO1A2u44enZWZdiZvY5fcr9hRHxIqBOXj6lnLVkbbf+\nNXz/hDH84ol3eGXBco5oGJp1SWZmW/hO6ox955gGhg/uz8/+bRabPUaTmVUQB0TGBvTtzVWn789b\nH6zigVebsy7HzGwLB0QFOOvgvTn0C7Vc9+Rs1qxvzbocMzPAAVERJHHNXx/AR2vWc/2TPmFtZpXB\nAVEhDhlZy/ijG5j80gJeWbA863LMzBwQleQnp+7HiNoBXPHAm3y6wVOTmlm2HBAVZJd+ffjf5xzE\ngr+s5acPv+U5I8wsUw6ICnPMvsO47JSxPPTaB/zu5YVZl2NmOeaAqEA/OHksJ3yxjn96dCYvvFud\nAxKaWfVzQFSgXr3Ev1xwKPvusRvfv2u6T1qbWSYcEBVq8IAa7rz4SIbX9ufC307jj28tzrokM8sZ\nB0QFq9utHw9ccgwH7j2If7jnVa55ZIavbjKzsnFAVLihu/Tld987iouPHcXkl97npOuf5a6XFviO\nazNLnar5UsrGxsZoamrKuoyyaVqwnGv/+A5N769gQE1vTvjiMI4avTv77zWIhmEDGbZrP2p6O/PN\nbNskTY+IxpLrOSCqS0Tw6sKVPPhqM3+a08Ki5Z9+5vX+Nb3YtV8N/fr0QoJeEr2SR3U2yHoGKupf\nXQUVU0GlVMx9OJVRRUGF/EoA+PuvfoFLThzTrfd2NSDKPh+E7RhJHL7PEA7fZwgAi1d9ynvL1rLg\nL2tZsXYDq9e3snrdRja0BhFBAJsj2BwUhhOvoJCooFJQBaVn5VRCxfxRUSFlAJXzb2VE7YDUv8MB\nUeWGDx7A8MEDOG7ssKxLMbMexgeszcysKAeEmZkV5YAwM7OiHBBmZlZUxQWEpNMkzZY0V9JVWddj\nZpZXFRUQknoDvwROB74MXCDpy9lWZWaWTxUVEMCRwNyImBcRG4DfA+MyrsnMLJcqLSBGAIvaLTcn\nbWZmVmaVdqNcsVsUP3Nzu6SJwMRkcY2k2d38rmHAR918b7XyNueDtzkfdmSb9+nKSpUWEM3AyHbL\n9cCH7VeIiEnApB39IklNXRmLpCfxNueDtzkfyrHNlXaI6RVgrKRRkvoC5wOPZlyTmVkuVVQPIiJa\nJf1X4EmgN3BbRMzMuCwzs1yqqIAAiIjHgcfL8FU7fJiqCnmb88HbnA+pb3NVzwdhZmbpqbRzEGZm\nViFyGRA9dTgPSSMlPSvpbUkzJV2WtA+V9LSkOcnjkKRdkm5Ofg9vSjos2y3oHkm9Jb0m6bFkeZSk\nacn23pdc8ICkfsny3OT1hizr3hGSaiU9IOmdZH8f3ZP3s6TLk3/TMyTdK6l/T9zPkm6TtEzSjHZt\n271fJY1P1p8jaXx368ldQPTw4TxagR9HxJeAo4BLk227CpgSEWOBKckyFH4HY5OficAt5S95p7gM\neLvd8i+AG5PtXQFMSNonACsiYl/gxmS9avXPwBMRsT9wMIXt75H7WdII4AdAY0QcSOEClvPpmfv5\nDuC0Dm3btV8lDQWuAb5KYXSKa9pCZbtFRK5+gKOBJ9stXw1cnXVdKW3rI8DXgdnA8KRtODA7ef5r\n4IJ2629Zr1p+KNwrMwU4GXiMws2WHwF9Ou5vClfHHZ0875Osp6y3oRvbPAiY37H2nrqf2TrCwtBk\nvz0GnNpT9zPQAMzo7n4FLgB+3a79M+ttz0/uehDkZDiPpFt9KDAN2DMiFgMkj3skq/WE38VNwBXA\n5mR5d2BlRLQmy+23acv2Jq+vStavNqOBFuD25NDabyXtQg/dzxHxAXA9sBBYTGG/Tafn7+c227tf\nd9r+zmNAlBzOo9pJ2hV4EPhhRHy8rVWLtFXN70LSmcCyiJjevrnIqtGF16pJH+Aw4JaIOBRYy9bD\nDsVU9XYnh0fGAaOAvYFdKBxe6ain7edSOtvOnbb9eQyIksN5VDNJNRTC4Z6IeChpXippePL6cGBZ\n0l7tv4tjgbMkLaAw8u/JFHoUtZLa7vFpv01btjd5fTCwvJwF7yTNQHNETEuWH6AQGD11P38NmB8R\nLRGxEXgIOIaev5/bbO9+3Wn7O48B0WOH85Ak4Fbg7Yi4od1LjwJtVzKMp3Buoq3928nVEEcBq9q6\nstUgIq6OiPqIaKCwH5+JiAuBZ4Fzk9U6bm/b7+HcZP2q+8syIpYAiyTtlzSdAsyih+5nCoeWjpI0\nMPk33ra9PXo/t7O9+/VJ4K8kDUl6X3+VtG2/rE/IZHQS6AzgXeA94KdZ17MTt+s4Cl3JN4HXk58z\nKBx/nQLMSR6HJuuLwhVd7wFvUbhKJPPt6Oa2nwQ8ljwfDbwMzAXuB/ol7f2T5bnJ66OzrnsHtvcQ\noCnZ1/8PGNKT9zPwv4B3gBnAXUC/nrifgXspnGfZSKEnMKE7+xW4ONn+ucBF3a3Hd1KbmVlReTzE\nZGZmXeCAMDOzohwQZmZWlAPCzMyKckCYmVlRDgizjEg6qW0EWrNK5IAwM7OiHBBmJUj6pqSXJb0u\n6dfJ/BNrJP0fSa9KmiKpLln3EElTk/H5H243dv++kv5d0hvJe8YkH79ru3kd7knuFDarCA4Is22Q\n9CXgPODYiDgE2ARcSGHAuFcj4jDgeQrj7wPcCVwZEQdRuLu1rf0e4JcRcTCFcYTahro4FPghhblJ\nRlMYX8qsIvQpvYpZrp0CHA68kvxxP4DCYGmbgfuSde4GHpI0GKiNiOeT9snA/ZJ2A0ZExMMAEbEO\nIPm8lyOiOVl+ncJcAC+mv1lmpTkgzLZNwOSIuPozjdL/7LDetsas2dZho/Xtnm/C/01aBfEhJrNt\nmwKcK2kP2DI/8D4U/ttpG0n074EXI2IVsELS8Un7t4DnozAnR7Oks5PP6CdpYFm3wqwb/NeK2TZE\nxCxJ/wN4SlIvCqNsXkphkp4DJE2nMGPZeclbxgO/SgJgHnBR0v4t4NeSfpZ8xjfKuBlm3eLRXM26\nQdKaiNg16zrM0uRDTGZmVpR7EGZmVpR7EGZmVpQDwszMinJAmJlZUQ4IMzMrygFhZmZFOSDMzKyo\n/w/pSJbQibyOgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model\n",
    "Now we run the test set through the model to see if the loss calculation resembles the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.57392597\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([5.9351])                        tensor([5.7000])\n",
      " 2. tensor([4.7169])                        tensor([6.5000])\n",
      " 3. tensor([6.5764])                        tensor([6.1000])\n",
      " 4. tensor([5.1535])                        tensor([4.9000])\n",
      " 5. tensor([10.0742])                       tensor([7.3000])\n",
      " 6. tensor([5.5340])                        tensor([5.3000])\n",
      " 7. tensor([8.9779])                        tensor([9.3000])\n",
      " 8. tensor([9.0194])                        tensor([8.5000])\n",
      " 9. tensor([5.4973])                        tensor([4.1000])\n",
      "10. tensor([8.8415])                        tensor([8.1000])\n",
      "11. tensor([4.6676])                        tensor([3.7000])\n",
      "12. tensor([6.1553])                        tensor([6.9000])\n",
      "13. tensor([4.3723])                        tensor([5.3000])\n",
      "14. tensor([8.8304])                        tensor([7.7000])\n",
      "15. tensor([10.3429])                       tensor([11.7000])\n",
      "16. tensor([5.4253])                        tensor([4.1000])\n",
      "17. tensor([5.9984])                        tensor([8.1000])\n",
      "18. tensor([5.9468])                        tensor([6.1000])\n",
      "19. tensor([4.9695])                        tensor([4.5000])\n",
      "20. tensor([16.6034])                       tensor([20.1000])\n",
      "21. tensor([8.1620])                        tensor([7.7000])\n",
      "22. tensor([5.7226])                        tensor([6.5000])\n",
      "23. tensor([6.9785])                        tensor([6.1000])\n",
      "24. tensor([4.4926])                        tensor([5.3000])\n",
      "25. tensor([4.0590])                        tensor([3.7000])\n",
      "26. tensor([4.4487])                        tensor([4.5000])\n",
      "27. tensor([18.6178])                       tensor([25.8700])\n",
      "28. tensor([8.8670])                        tensor([7.3000])\n",
      "29. tensor([6.9234])                        tensor([5.7000])\n",
      "30. tensor([11.4128])                       tensor([8.5000])\n",
      "31. tensor([13.0176])                       tensor([10.5000])\n",
      "32. tensor([13.6224])                       tensor([13.3000])\n",
      "33. tensor([5.1584])                        tensor([5.3000])\n",
      "34. tensor([7.6501])                        tensor([8.1000])\n",
      "35. tensor([6.8289])                        tensor([5.3000])\n",
      "36. tensor([4.3122])                        tensor([4.1000])\n",
      "37. tensor([2.9577])                        tensor([2.5000])\n",
      "38. tensor([8.9821])                        tensor([8.5000])\n",
      "39. tensor([8.8475])                        tensor([8.9000])\n",
      "40. tensor([17.2852])                       tensor([12.1000])\n",
      "41. tensor([4.6542])                        tensor([4.1000])\n",
      "42. tensor([5.4848])                        tensor([5.7000])\n",
      "43. tensor([7.6436])                        tensor([6.5000])\n",
      "44. tensor([5.8038])                        tensor([5.7000])\n",
      "45. tensor([4.6248])                        tensor([4.1000])\n",
      "46. tensor([27.3486])                       tensor([27.8700])\n",
      "47. tensor([11.2318])                       tensor([11.3000])\n",
      "48. tensor([6.4442])                        tensor([5.7000])\n",
      "49. tensor([14.0349])                       tensor([15.7000])\n",
      "50. tensor([11.2625])                       tensor([8.9000])\n",
      "51. tensor([17.5776])                       tensor([15.9000])\n",
      "52. tensor([13.9531])                       tensor([13.7000])\n",
      "53. tensor([6.5622])                        tensor([6.9000])\n",
      "54. tensor([8.1888])                        tensor([11.7000])\n",
      "55. tensor([3.9806])                        tensor([4.1000])\n",
      "56. tensor([25.7906])                       tensor([23.7000])\n",
      "57. tensor([6.5049])                        tensor([7.7000])\n",
      "58. tensor([6.9916])                        tensor([7.3000])\n",
      "59. tensor([5.1066])                        tensor([5.3000])\n",
      "60. tensor([9.0657])                        tensor([12.5000])\n",
      "61. tensor([9.6268])                        tensor([8.5000])\n",
      "62. tensor([9.1951])                        tensor([7.7000])\n",
      "63. tensor([18.8694])                       tensor([15.3000])\n",
      "64. tensor([15.3793])                       tensor([12.5000])\n",
      "65. tensor([4.8490])                        tensor([4.1000])\n",
      "66. tensor([11.2053])                       tensor([10.9000])\n",
      "67. tensor([3.0025])                        tensor([2.5000])\n",
      "68. tensor([10.7960])                       tensor([24.5000])\n",
      "69. tensor([5.8103])                        tensor([4.1000])\n",
      "70. tensor([5.9153])                        tensor([6.1000])\n",
      "71. tensor([4.3209])                        tensor([4.1000])\n",
      "72. tensor([5.1897])                        tensor([4.9000])\n",
      "73. tensor([26.8660])                       tensor([26.5000])\n",
      "74. tensor([14.4186])                       tensor([13.7000])\n",
      "75. tensor([6.1869])                        tensor([7.3000])\n",
      "76. tensor([11.5258])                       tensor([10.5000])\n",
      "77. tensor([11.7629])                       tensor([10.1000])\n",
      "78. tensor([4.8780])                        tensor([9.3000])\n",
      "79. tensor([6.7100])                        tensor([5.7000])\n",
      "80. tensor([3.8303])                        tensor([4.1000])\n",
      "81. tensor([15.0898])                       tensor([12.1000])\n",
      "82. tensor([6.4430])                        tensor([5.7000])\n",
      "83. tensor([9.0043])                        tensor([9.7000])\n",
      "84. tensor([6.5237])                        tensor([8.5000])\n",
      "85. tensor([13.5751])                       tensor([12.5000])\n",
      "86. tensor([10.8481])                       tensor([10.5000])\n",
      "87. tensor([14.6166])                       tensor([41.5000])\n",
      "88. tensor([7.7631])                        tensor([7.3000])\n",
      "89. tensor([4.4774])                        tensor([4.1000])\n",
      "90. tensor([6.9318])                        tensor([8.9000])\n",
      "91. tensor([5.2952])                        tensor([14.1000])\n",
      "92. tensor([23.6661])                       tensor([35.8700])\n",
      "93. tensor([8.8729])                        tensor([8.5000])\n",
      "94. tensor([14.8063])                       tensor([13.7000])\n",
      "95. tensor([5.8293])                        tensor([6.5000])\n",
      "96. tensor([3.8397])                        tensor([3.7000])\n",
      "97. tensor([7.1149])                        tensor([6.9000])\n",
      "98. tensor([4.5141])                        tensor([4.9000])\n",
      "99. tensor([8.7219])                        tensor([10.9000])\n",
      "100. tensor([9.7488])                        tensor([8.5000])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test[:100]):\n",
    "        y_val = model(data)\n",
    "        print(f'{i+1:2}. {str(y_val):38}  {y_test[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
