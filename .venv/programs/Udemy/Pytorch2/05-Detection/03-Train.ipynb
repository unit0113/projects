{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "saved-cartoon",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "We are ready to train the Cardiac Detection Model now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-float",
   "metadata": {},
   "source": [
    "## Imports:\n",
    "\n",
    "* torch and torchvision for model and dataloader creation\n",
    "* pytorch lightning for efficient and easy training implementation\n",
    "* ModelCheckpoint and TensorboardLogger for checkpoint saving and logging\n",
    "* numpy data loading\n",
    "* cv2 for drawing rectangles on images\n",
    "* imgaug for augmentation pipeline\n",
    "* Our CardiacDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "from dataset import CardiacDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-switch",
   "metadata": {},
   "source": [
    "We create the dataset objects and the augmentation parameters to specify the augmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_path = \"Processed-Heart-Detection/train/\"\n",
    "train_subjects = \"train_subjects.npy\"\n",
    "val_root_path = \"Processed-Heart-Detection/val/\"\n",
    "val_subjects = \"val_subjects.npy\"\n",
    "\n",
    "train_transforms = iaa.Sequential([\n",
    "                                iaa.GammaContrast(),\n",
    "                                iaa.Affine(\n",
    "                                    scale=(0.8, 1.2),\n",
    "                                    rotate=(-10, 10),\n",
    "                                    translate_px=(-10, 10)\n",
    "                                )\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CardiacDataset(\"rsna_heart_detection.csv\", train_subjects, train_root_path, train_transforms)\n",
    "val_dataset = CardiacDataset(\"rsna_heart_detection.csv\", val_subjects, val_root_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CardiacDataset(\n",
    "    \"./rsna_heart_detection.csv\",\n",
    "     train_subjects,\n",
    "     train_root_path,\n",
    "     augs = train_transforms)\n",
    "\n",
    "val_dataset = CardiacDataset(\n",
    "    \"./rsna_heart_detection.csv\",\n",
    "     val_subjects,\n",
    "     val_root_path,\n",
    "     augs=None)\n",
    "\n",
    "print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-beast",
   "metadata": {},
   "source": [
    "Adapt batch size and num_workers according to your computing hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8#TODO\n",
    "num_workers = 4# TODO\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-forum",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-processor",
   "metadata": {},
   "source": [
    "We use the same architecture as we used in the classifcation task with some small adaptations:\n",
    "\n",
    "1. 4 outputs: Instead of predicting a binary label we need to estimate the location of the heart (xmin, ymin, xmax, ymax).\n",
    "2. Loss function: Instead of using a cross entropy loss, we are going to use the L2 loss (Mean Squared Error), as we are dealing with continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardiacDetectionModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = torch.nn.Linear(in_features=512 ,out_features=4)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Train Loss\", loss)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            self.log_images(x_ray.cpu(), pred.cpu(), label.cpu(), \"Train\")\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Val Loss\", loss)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            self.log_images(x_ray.cpu(), pred.cpu(), label.cpu(), \"Val\")\n",
    "        return loss\n",
    "    \n",
    "    def log_images(self, x_ray, pred, label, name):\n",
    "        results = []\n",
    "        \n",
    "        for i in range(4):\n",
    "            coords_labels = label[i]\n",
    "            coords_pred = pred[i]\n",
    "            \n",
    "            img = ((x_ray[i] * 0.252)+0.494).numpy()[0]\n",
    "            \n",
    "            x0, y0 = coords_labels[0].int().item(), coords_labels[1].int().item()\n",
    "            x1, y1 = coords_labels[2].int().item(), coords_labels[3].int().item()\n",
    "            img = cv2.rectangle(img, (x0, y0), (x1, y1), (0, 0, 0), 2)\n",
    "            \n",
    "            x0, y0 = coords_pred[0].int().item(), coords_pred[1].int().item()\n",
    "            x1, y1 = coords_pred[2].int().item(), coords_pred[3].int().item()\n",
    "            img = cv2.rectangle(img, (x0, y0), (x1, y1), (1, 1, 1), 2)\n",
    "            \n",
    "            results.append(torch.tensor(img).unsqueeze(0))\n",
    "        \n",
    "        grid = torchvision.utils.make_grid(results, 2)\n",
    "        self.logger.experiment.add_image(name, grid, self.global_step)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        #Caution! You always need to return a list here (just pack your optimizer into one :))\n",
    "        return [self.optimizer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardiacDetectionModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Change conv1 from 3 to 1 input channels\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Change out_feature of the last fully connected layer (called fc in resnet18) from 1000 to 4\n",
    "        self.model.fc = torch.nn.Linear(in_features=512, out_features=4)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    def forward(self, data):\n",
    "        pred = self.model(data)\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()  # Convert label to float (just needed for loss computation)\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label)  # Compute the loss\n",
    "        \n",
    "        # Log loss\n",
    "        self.log(\"Train Loss\", loss)\n",
    "        if batch_idx % 50 == 0:\n",
    "            self.log_images(x_ray.cpu(), pred.cpu(), label.cpu(), \"Train\")\n",
    "\n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Same steps as in the training_step\n",
    "        x_ray, label = batch\n",
    "        label = label\n",
    "\n",
    "        label = label.float()  # Convert label to float (just needed for loss computation)\n",
    "        pred = self(x_ray)\n",
    "        \n",
    "        loss = self.loss_fn(pred, label)\n",
    "        self.log(\"Val Loss\", loss)\n",
    "        if batch_idx % 50 == 0:\n",
    "            self.log_images(x_ray.cpu(), pred.cpu(), label.cpu(), \"Val\")\n",
    "        return loss\n",
    "    \n",
    "    def log_images(self, x_ray, pred, label, name):\n",
    "        results = []\n",
    "        \n",
    "        # Here we create a grid consisting of 4 predictions\n",
    "        for i in range(4):\n",
    "            coords_labels = label[i]\n",
    "            coords_pred = pred[i]\n",
    "            img = ((x_ray[i] * 0.252)+0.494).numpy()[0]\n",
    "            \n",
    "            # Extract the coordinates from the label\n",
    "            x0, y0 = coords_labels[0].int().item(), coords_labels[1].int().item()\n",
    "            x1, y1 = coords_labels[2].int().item(), coords_labels[3].int().item()\n",
    "            img = cv2.rectangle(img, (x0, y0), (x1, y1), (0, 0, 0), 2)\n",
    "            \n",
    "            # Extract the coordinates from the prediction           \n",
    "            x0, y0 = coords_pred[0].int().item(), coords_pred[1].int().item()\n",
    "            x1, y1 = coords_pred[2].int().item(), coords_pred[3].int().item()\n",
    "            img = cv2.rectangle(img, (x0, y0), (x1, y1), (1, 1, 1), 2)\n",
    "            \n",
    "            \n",
    "            results.append(torch.tensor(img).unsqueeze(0))\n",
    "        grid = torchvision.utils.make_grid(results, 2)\n",
    "        self.logger.experiment.add_image(f\"{name} Prediction vs Label\", grid, self.global_step)\n",
    "\n",
    "            \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #Caution! You always need to return a list here (just pack your optimizer into one :))\n",
    "        return [self.optimizer]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "model = CardiacDetectionModel()  # Instanciate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='Val Loss',\n",
    "    save_top_k=10,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-cylinder",
   "metadata": {},
   "source": [
    "Train for at least 50 epochs to get a decent result.\n",
    "100 epochs lead to great results.\n",
    "\n",
    "You can train this on a CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trainer\n",
    "# Change the gpus parameter to the number of available gpus in your computer. Use 0 for CPU training\n",
    "\n",
    "gpus = 1 #TODO\n",
    "trainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(\"./logs\"), log_every_n_steps=1,\n",
    "                     default_root_dir=\"./weights\", callbacks=checkpoint_callback,\n",
    "                     max_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-bunch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the detection model\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-designer",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-royalty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.load_from_checkpoint(\"weight.ckpt\")\n",
    "model.eval();\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-contemporary",
   "metadata": {},
   "source": [
    "Compute prediction for all validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-witness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in val_dataset:\n",
    "        data = data.to(device).float().unsqueeze(0)\n",
    "        pred = model(data)[0].cpu()\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "        \n",
    "preds=torch.stack(preds)\n",
    "labels=torch.stack(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-cleanup",
   "metadata": {},
   "source": [
    "Compute mean deviation between prediction and labels for each coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-construction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abs(preds-labels).mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-video",
   "metadata": {},
   "source": [
    "Example prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-shield",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IDX = 60  # Feel free to inspect all validation samples by changing the index\n",
    "img, label = val_dataset[IDX]\n",
    "current_pred = preds[IDX]\n",
    "\n",
    "fig, axis = plt.subplots(1, 1)\n",
    "axis.imshow(img[0], cmap=\"bone\")\n",
    "heart = patches.Rectangle((current_pred[0], current_pred[1]), current_pred[2]-current_pred[0],\n",
    "                          current_pred[3]-current_pred[1], linewidth=1, edgecolor='r', facecolor='none')\n",
    "axis.add_patch(heart)\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-snapshot",
   "metadata": {},
   "source": [
    "Awesome, looks like we got a working heart detection!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
